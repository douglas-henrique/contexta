# ğŸ§ª Guia Completo de Testes - Contexta

## ğŸ“Š VisÃ£o Geral

SuÃ­te completa de testes unitÃ¡rios para garantir qualidade e confiabilidade do cÃ³digo.

### EstatÃ­sticas
- **Total de Arquivos de Teste**: 12
- **MÃ³dulos Cobertos**: Core, Ingest, API
- **Tipos de Teste**: UnitÃ¡rios, IntegraÃ§Ã£o (CI/CD ready)
- **Framework**: pytest + pytest-cov + pytest-mock

---

## ğŸ—‚ï¸ Estrutura de Testes

```
tests/
â”œâ”€â”€ conftest.py                    # ğŸ”§ Fixtures compartilhadas
â”‚   â”œâ”€â”€ mock_openai_client         # Mock do OpenAI
â”‚   â”œâ”€â”€ mock_qdrant_client         # Mock do Qdrant
â”‚   â”œâ”€â”€ sample_text                # Textos de exemplo
â”‚   â”œâ”€â”€ sample_chunks               # Chunks de exemplo
â”‚   â”œâ”€â”€ sample_embeddings          # Embeddings de exemplo
â”‚   â””â”€â”€ sample_search_results      # Resultados de busca
â”‚
â”œâ”€â”€ test_core/                     # âœ… Testes do Core (Framework-agnostic)
â”‚   â”œâ”€â”€ test_llm.py                # Testes de LLM providers
â”‚   â”‚   â”œâ”€â”€ TestOpenAILLM
â”‚   â”‚   â”‚   â”œâ”€â”€ test_initialization
â”‚   â”‚   â”‚   â”œâ”€â”€ test_generate
â”‚   â”‚   â”‚   â”œâ”€â”€ test_generate_with_parameters
â”‚   â”‚   â”‚   â””â”€â”€ test_generate_stream
â”‚   â”‚   
â”‚   â”œâ”€â”€ test_prompts.py            # Testes de Prompt Builders
â”‚   â”‚   â””â”€â”€ TestRAGPromptBuilder
â”‚   â”‚       â”œâ”€â”€ test_initialization
â”‚   â”‚       â”œâ”€â”€ test_build_basic
â”‚   â”‚       â”œâ”€â”€ test_build_with_max_length
â”‚   â”‚       â””â”€â”€ test_build_with_sources
â”‚   â”‚
â”‚   â””â”€â”€ test_reranker.py           # Testes de Re-rankers
â”‚       â””â”€â”€ TestSimpleReranker
â”‚           â”œâ”€â”€ test_rerank_by_score
â”‚           â”œâ”€â”€ test_rerank_top_k
â”‚           â””â”€â”€ test_rerank_empty_results
â”‚
â”œâ”€â”€ test_ingest/                   # ğŸ“¥ Testes do Ingest Service
â”‚   â”œâ”€â”€ test_chunking.py           # Testes de Chunking
â”‚   â”‚   â””â”€â”€ TestSemanticChunking
â”‚   â”‚       â”œâ”€â”€ test_basic_chunking
â”‚   â”‚       â”œâ”€â”€ test_chunk_size
â”‚   â”‚       â”œâ”€â”€ test_chunk_overlap
â”‚   â”‚       â””â”€â”€ test_empty_text
â”‚   â”‚
â”‚   â”œâ”€â”€ test_loaders.py            # Testes de Document Loaders
â”‚   â”‚   â”œâ”€â”€ TestPDFLoader
â”‚   â”‚   â”‚   â””â”€â”€ test_load_pdf
â”‚   â”‚   â””â”€â”€ TestLoaderFactory
â”‚   â”‚       â”œâ”€â”€ test_get_loader_pdf
â”‚   â”‚       â”œâ”€â”€ test_load_document_pdf
â”‚   â”‚       â””â”€â”€ test_load_document_txt
â”‚   â”‚
â”‚   â”œâ”€â”€ test_embeddings.py         # Testes de Embeddings
â”‚   â”‚   â””â”€â”€ TestOpenAIEmbeddings
â”‚   â”‚       â”œâ”€â”€ test_embed_texts
â”‚   â”‚       â””â”€â”€ test_embed_texts_custom_model
â”‚   â”‚
â”‚   â””â”€â”€ test_vectorstore.py        # Testes de Vector Store
â”‚       â””â”€â”€ TestQdrantVectorStore
â”‚           â”œâ”€â”€ test_ensure_collection_exists
â”‚           â”œâ”€â”€ test_store_embeddings
â”‚           â”œâ”€â”€ test_search
â”‚           â””â”€â”€ test_search_with_filters
â”‚
â””â”€â”€ test_api/                      # ğŸš€ Testes da API
    â””â”€â”€ test_main.py               # Testes de Endpoints
        â””â”€â”€ TestAPIEndpoints
            â”œâ”€â”€ test_root_endpoint
            â”œâ”€â”€ test_health_endpoint
            â”œâ”€â”€ test_query_endpoint
            â”œâ”€â”€ test_query_endpoint_no_results
            â””â”€â”€ test_query_endpoint_validation
```

---

## ğŸš€ Como Executar

### MÃ©todo 1: Script de Teste (Recomendado)

```bash
# Todos os testes
./run_tests.sh

# Testes com cobertura (gera relatÃ³rio HTML)
./run_tests.sh cov

# Apenas testes unitÃ¡rios
./run_tests.sh unit

# Apenas testes de integraÃ§Ã£o
./run_tests.sh integration

# Testes rÃ¡pidos (exclui @pytest.mark.slow)
./run_tests.sh fast

# Modo watch (reexecuta ao salvar arquivos)
./run_tests.sh watch
```

### MÃ©todo 2: Poetry Direto

```bash
# Todos os testes com verbosidade
poetry run pytest -v

# Com cobertura
poetry run pytest --cov --cov-report=term-missing

# Testes especÃ­ficos
poetry run pytest tests/test_core/test_llm.py

# Uma classe especÃ­fica
poetry run pytest tests/test_core/test_llm.py::TestOpenAILLM

# Um teste especÃ­fico
poetry run pytest tests/test_core/test_llm.py::TestOpenAILLM::test_generate

# Parar no primeiro erro
poetry run pytest -x

# Ver outputs (print statements)
poetry run pytest -s

# Modo watch
poetry run pytest-watch
```

### MÃ©todo 3: Makefile

```bash
# Todos os testes
make test

# Com cobertura
make test-cov

# Apenas unitÃ¡rios
make test-unit

# Apenas integraÃ§Ã£o
make test-integration
```

### MÃ©todo 4: Docker

```bash
# Executar testes no container
docker-compose run --rm ingest poetry run pytest

# Com cobertura
docker-compose run --rm ingest poetry run pytest --cov

# Usando make
make docker-test
```

---

## ğŸ“ˆ Cobertura de CÃ³digo

### Gerar RelatÃ³rio

```bash
# Terminal
poetry run pytest --cov --cov-report=term-missing

# HTML (abre no navegador)
poetry run pytest --cov --cov-report=html
open htmlcov/index.html

# XML (para CI/CD)
poetry run pytest --cov --cov-report=xml
```

### Meta de Cobertura

- **Core**: 90%+
- **Ingest**: 85%+
- **API**: 80%+
- **Overall**: 85%+

---

## ğŸ¯ Tipos de Testes

### Testes UnitÃ¡rios (`@pytest.mark.unit`)

- Testam componentes isolados
- Usam mocks para dependÃªncias externas
- RÃ¡pidos de executar (<1s por teste)
- NÃ£o requerem serviÃ§os externos

**Exemplo:**
```python
@pytest.mark.unit
def test_generate(mock_openai_client):
    llm = OpenAILLM(api_key="test")
    result = llm.generate("Test prompt")
    assert result == "Generated text"
```

### Testes de IntegraÃ§Ã£o (`@pytest.mark.integration`)

- Testam interaÃ§Ã£o entre componentes
- Podem usar serviÃ§os reais (Qdrant, etc.)
- Mais lentos
- Ideais para CI/CD pipeline

**Exemplo:**
```python
@pytest.mark.integration
def test_end_to_end_query():
    # Usa Qdrant real, OpenAI real
    response = client.post("/query", json={"query": "test"})
    assert response.status_code == 200
```

### Testes Lentos (`@pytest.mark.slow`)

- Testes que demoram >5s
- Geralmente testes de integraÃ§Ã£o ou end-to-end
- Podem ser pulados em desenvolvimento rÃ¡pido

```bash
# Pular testes lentos
poetry run pytest -m "not slow"
```

---

## ğŸ”§ Fixtures DisponÃ­veis

### Mock Clients

```python
def test_with_openai(mock_openai_client):
    """mock_openai_client jÃ¡ configurado com respostas fake"""
    pass

def test_with_qdrant(mock_qdrant_client):
    """mock_qdrant_client jÃ¡ configurado com resultados fake"""
    pass
```

### Sample Data

```python
def test_chunking(sample_text):
    """sample_text contÃ©m texto de exemplo"""
    chunks = semantic_chunk(sample_text)
    assert len(chunks) > 0

def test_embeddings(sample_chunks):
    """sample_chunks contÃ©m lista de chunks"""
    pass

def test_search(sample_search_results):
    """sample_search_results contÃ©m resultados de busca mock"""
    pass
```

---

## ğŸ§© Boas PrÃ¡ticas Implementadas

### 1. Arrange-Act-Assert (AAA)

```python
def test_example():
    # Arrange: setup
    llm = OpenAILLM(api_key="test")
    
    # Act: execute
    result = llm.generate("prompt")
    
    # Assert: verify
    assert result == "expected"
```

### 2. Descriptive Test Names

```python
# âœ… Bom
def test_generate_with_invalid_api_key_raises_error():
    pass

# âŒ Ruim
def test_generate_error():
    pass
```

### 3. One Assert Per Test (quando possÃ­vel)

```python
# âœ… Bom
def test_response_has_answer():
    assert "answer" in response.json()

def test_response_has_sources():
    assert "sources" in response.json()

# âŒ Evitar mÃºltiplos asserts nÃ£o relacionados
def test_response():
    assert "answer" in response.json()
    assert "sources" in response.json()
    assert response.status_code == 200
```

### 4. Usar Mocks para APIs Externas

```python
# âœ… Sempre use mocks para OpenAI, Qdrant em testes unitÃ¡rios
@patch('ingest.embeddings.openai.OpenAI')
def test_embed_texts(mock_openai):
    # Teste rÃ¡pido, sem custo de API
    pass

# âŒ Nunca faÃ§a chamadas reais em testes unitÃ¡rios
def test_embed_texts_real():
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    # Isso Ã© lento e custa dinheiro!
```

### 5. Organize em Classes

```python
class TestOpenAILLM:
    """Agrupa todos os testes relacionados ao OpenAILLM"""
    
    def test_initialization(self):
        pass
    
    def test_generate(self):
        pass
    
    def test_generate_stream(self):
        pass
```

---

## ğŸš¨ Troubleshooting

### Import Errors

```bash
# Adicionar PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
poetry run pytest
```

### Testes Falhando Localmente mas Passando no CI

- Verifique variÃ¡veis de ambiente (`.env` vs CI secrets)
- Verifique dependÃªncias (versÃµes diferentes?)
- Verifique sistema operacional (paths, line endings)

### Mock nÃ£o estÃ¡ funcionando

```python
# âŒ Ruim: mock no lugar errado
@patch('core.llm.openai.OpenAI')  # ImportaÃ§Ã£o original

# âœ… Bom: mock onde Ã© usado
@patch('tests.test_core.test_llm.OpenAI')  # Onde o teste importa
```

### Testes muito lentos

- Use `-n auto` para paralelizaÃ§Ã£o: `pytest -n auto`
- Pule testes lentos: `pytest -m "not slow"`
- Verifique se estÃ¡ usando mocks corretamente

---

## ğŸ”„ CI/CD

### GitHub Actions

Os testes rodam automaticamente em cada push/PR.

**Workflow**: `.github/workflows/tests.yml`

- âœ… Executa em Python 3.12
- âœ… Sobe Qdrant como service
- âœ… Executa todos os testes
- âœ… Gera relatÃ³rio de cobertura
- âœ… Upload para Codecov (opcional)
- âœ… Linting (flake8, black, isort)

### Badges (adicione ao README.md)

```markdown
![Tests](https://github.com/seu-usuario/contexta/workflows/Tests/badge.svg)
[![codecov](https://codecov.io/gh/seu-usuario/contexta/branch/main/graph/badge.svg)](https://codecov.io/gh/seu-usuario/contexta)
```

---

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o Pytest

- [pytest docs](https://docs.pytest.org/)
- [pytest-cov](https://pytest-cov.readthedocs.io/)
- [pytest-mock](https://pytest-mock.readthedocs.io/)

### PrÃ³ximos Passos

- [ ] Adicionar testes end-to-end completos
- [ ] Adicionar testes de performance
- [ ] Adicionar testes de carga (locust, k6)
- [ ] Configurar Codecov para relatÃ³rios de cobertura
- [ ] Adicionar mutation testing (mutmut)
- [ ] Adicionar property-based testing (hypothesis)

---

## âœ… Checklist de Testes

Antes de fazer PR, garanta que:

- [ ] Todos os testes passam: `./run_tests.sh`
- [ ] Cobertura >85%: `./run_tests.sh cov`
- [ ] Linting ok: `make lint`
- [ ] FormataÃ§Ã£o ok: `make format`
- [ ] Novos testes foram adicionados para novas features
- [ ] Testes usam mocks apropriados
- [ ] Testes tÃªm nomes descritivos
- [ ] DocumentaÃ§Ã£o atualizada se necessÃ¡rio

---

**ğŸ‰ Pronto! Agora vocÃª tem uma suÃ­te de testes profissional para o Contexta!**

